{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code v1.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7vVHKxhODBo"
      },
      "source": [
        "# TM10007 Machine Learning Assignment 2021\n",
        "Linda Chen (4648242), Yaro Roodenburg (4553322), Laurent Coopmans (4672577) & Killian Zijlstra (4652460)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "745E2eyAwO5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1291e964-8b83-44bf-bc60-56b9d31dfcdb"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR959pCxR1f"
      },
      "source": [
        "# import all packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import model_selection\n",
        "from skimage import data\n",
        "from adni.load_data import load_data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import itertools as it\n",
        "import seaborn\n",
        "\n",
        "# Classifiers\n",
        "#from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Feature selection\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import plot_confusion_matrix\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_JZ9gU8fIwZ"
      },
      "source": [
        "# Used function, from exercises from the course\n",
        "def plot_roc_curve(y_score, y_truth):\n",
        "    '''\n",
        "    Plot an ROC curve.\n",
        "    '''\n",
        "    # Only take scores for class = 1\n",
        "    y_score = y_score[:, 1]\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr, tpr, _ = roc_curve(y_truth, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to count frequency. Courtesy of:\n",
        "# https://www.geeksforgeeks.org/counting-the-frequencies-in-a-list-using-dictionary-in-python/\n",
        "def CountFrequency(my_list):\n",
        "      \n",
        "    # Creating an empty dictionary \n",
        "    freq = {}\n",
        "    for items in my_list:\n",
        "        freq[items] = my_list.count(items)\n",
        "      \n",
        "    for key, value in freq.items():\n",
        "        print (\"% d : % d\"%(key, value))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcSTiyDxCM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7b8116-ca70-4051-bb4f-bbd9110e8198"
      },
      "source": [
        "# Data loading functions\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "df_AD = data[data['label'] == 'AD']\n",
        "print(f'The number of samples with AD: {len(df_AD.index)}')\n",
        "\n",
        "df_CN = data[data['label'] == 'CN']\n",
        "print(f'The number of samples with no AD: {len(df_CN.index)}')\n",
        "\n",
        "features = data.columns.tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "# Split the dataset in train and test part\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data[features],\n",
        "#                                                     labels,\n",
        "#                                                     test_size=0.2,\n",
        "#                                                     stratify=labels,\n",
        "#                                                     random_state=8)\n",
        "# df = X_train\n",
        "# df_test = X_test\n",
        "# print(type(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yaro1\\\\miniconda3\\\\lib\\\\site-packages\\\\adni\\\\ADNI_radiomicFeatures.csv'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-6-91aa3b5d54f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Data loading functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The number of samples: {len(data.index)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The number of columns: {len(data.columns)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\adni\\load_data.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mthis_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADNI_radiomicFeatures.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yaro1\\\\miniconda3\\\\lib\\\\site-packages\\\\adni\\\\ADNI_radiomicFeatures.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZG7wx1UU35j",
        "outputId": "561a8e58-2dfc-4ad2-ff57-676fd4b2ecf2"
      },
      "source": [
        "# five time stratified random feature elimination\n",
        "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
        "labels_binary = [1 if label == 'CN' else 0 for label in labels]\n",
        "chosen_features = []\n",
        "\n",
        "for X_train, X_test in skf.split(data[features], labels_binary):\n",
        "  df = data.iloc[X_train]\n",
        "  df_test = data.iloc[X_test]\n",
        "\n",
        "  labels = df['label'].tolist()\n",
        "  df_AD = df[df['label'] == 'AD']\n",
        "  print(f'The number of samples with AD: {len(df_AD.index)}')\n",
        "\n",
        "  df_CN = df_test[df_test['label'] == 'CN']\n",
        "  print(f'The number of samples with no AD: {len(df_CN.index)}')\n",
        "\n",
        "  # First, remove the label column as that cannot be scaled\n",
        "  df_drop = df.drop(['label'], axis=1)\n",
        "  df_AD_scaled = df_AD.drop(['label'], axis=1)\n",
        "  df_CN_scaled = df_CN.drop(['label'], axis=1)\n",
        "  X_test_scaled = df_test.drop(['label'], axis=1)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  scaler.fit(df_drop)\n",
        "  df_scaled = scaler.transform(df_drop)\n",
        "  df_AD_scaled = scaler.transform(df_AD_scaled)\n",
        "  df_CN_scaled = scaler.transform(df_CN_scaled)\n",
        "  X_test_scaled = scaler.transform(X_test_scaled)\n",
        "\n",
        "  # transform back to dataframes\n",
        "  df_scaled = pd.DataFrame(df_scaled)\n",
        "  df_AD_scaled = pd.DataFrame(df_AD_scaled)\n",
        "  df_CN_scaled = pd.DataFrame(df_CN_scaled)\n",
        "  X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "\n",
        "  # extract all feature names\n",
        "  features = df.columns.tolist()\n",
        "  features.remove('label')\n",
        "\n",
        "  df_scaled.columns = features\n",
        "  df_AD_scaled.columns = features\n",
        "  df_CN_scaled.columns = features\n",
        "  X_test_scaled.columns = features\n",
        "\n",
        "  # Implement Mann whitney u test\n",
        "  p_values = list()\n",
        "\n",
        "  for feature in features:\n",
        "      # extract values form column of dataframe\n",
        "      values_AD = df_AD_scaled[feature].values.tolist()\n",
        "      values_CN = df_CN_scaled[feature].values.tolist()\n",
        "\n",
        "      if values_AD[0:50] == values_CN[0:50]:\n",
        "          continue\n",
        "      else:\n",
        "          # mann whitney u test\n",
        "          statistic, p_value = sp.stats.mannwhitneyu(values_AD,\n",
        "                                                     values_CN,\n",
        "                                                     use_continuity=True,\n",
        "                                                     alternative=None)\n",
        "          p_values.append(p_value)\n",
        "\n",
        "  # create dict from p_values and features\n",
        "  dict_p_values = dict(zip(features, p_values))\n",
        "\n",
        "  # Bonferroni correction\n",
        "  Bonferroni_corrected_p_values = {key:val for key, val in dict_p_values.items() if val < 0.05/len(p_values)}\n",
        "\n",
        "  # Create new DataFrame with only the significant features\n",
        "  df_sig_ft = df_scaled[Bonferroni_corrected_p_values.keys()]\n",
        "  df_sig_ft_test = X_test_scaled[Bonferroni_corrected_p_values.keys()]\n",
        "\n",
        "  # Create new list with labels for the selected features\n",
        "  # Separate labels AD from CN\n",
        "  labels = df['label'].tolist()\n",
        "  labels_test = df_test['label'].tolist()\n",
        "  labels_bin = [1 if label == 'CN' else 0 for label in labels]\n",
        "  labels_bin_test = [1 if label == 'CN' else 0 for label in labels_test]\n",
        "\n",
        "  # Convert dataframe to numpy array\n",
        "  arr_sig_ft = df_sig_ft.to_numpy()\n",
        "\n",
        "  # Greedy feature selection\n",
        "  # Create pipeline\n",
        "  estimator = SVC(kernel=\"linear\", max_iter=5000)\n",
        "  rfecv = RFECV(estimator, step=1)\n",
        "  model = SVC(kernel=\"linear\", max_iter=5000)\n",
        "  pipeline = Pipeline(steps=[('s', rfecv), ('m', model)])\n",
        "  # Evaluate model\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
        "  n_scores = cross_val_score(pipeline,\n",
        "                            arr_sig_ft,\n",
        "                            labels_bin,\n",
        "                            scoring='accuracy',\n",
        "                            cv=cv,\n",
        "                            n_jobs=-1,\n",
        "                            error_score='raise')\n",
        "  # Report performance\n",
        "  print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "  # Report which features were selected by RFE\n",
        "  # Fit RFECV\n",
        "  rfecv.fit(arr_sig_ft, labels_bin)\n",
        "  # Summarize all features\n",
        "  for i in range(arr_sig_ft.shape[1]):\n",
        "      print('Column: %d, Selected %s, Rank: %.3f' % (i,\n",
        "                                                    rfecv.support_[i],\n",
        "                                                    rfecv.ranking_[i]))\n",
        "      \n",
        "  # Select features with ranking 1.000 (relative ranking of importance)\n",
        "  # First, find their indices\n",
        "  feat_loc = np.where(rfecv.ranking_ == 1.000)\n",
        "  feat_select = df_sig_ft.columns[feat_loc]\n",
        "  feat_select_list = feat_select.values.tolist()\n",
        "  chosen_features.extend(feat_select_list)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples with AD: 415\n",
            "The number of samples with no AD: 67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.820 (0.053)\n",
            "Column: 0, Selected True, Rank: 1.000\n",
            "Column: 1, Selected False, Rank: 7.000\n",
            "Column: 2, Selected False, Rank: 29.000\n",
            "Column: 3, Selected False, Rank: 48.000\n",
            "Column: 4, Selected False, Rank: 4.000\n",
            "Column: 5, Selected True, Rank: 1.000\n",
            "Column: 6, Selected True, Rank: 1.000\n",
            "Column: 7, Selected False, Rank: 50.000\n",
            "Column: 8, Selected False, Rank: 93.000\n",
            "Column: 9, Selected False, Rank: 97.000\n",
            "Column: 10, Selected False, Rank: 69.000\n",
            "Column: 11, Selected False, Rank: 47.000\n",
            "Column: 12, Selected False, Rank: 46.000\n",
            "Column: 13, Selected False, Rank: 66.000\n",
            "Column: 14, Selected False, Rank: 76.000\n",
            "Column: 15, Selected False, Rank: 65.000\n",
            "Column: 16, Selected False, Rank: 62.000\n",
            "Column: 17, Selected False, Rank: 95.000\n",
            "Column: 18, Selected False, Rank: 91.000\n",
            "Column: 19, Selected False, Rank: 57.000\n",
            "Column: 20, Selected False, Rank: 43.000\n",
            "Column: 21, Selected False, Rank: 73.000\n",
            "Column: 22, Selected False, Rank: 5.000\n",
            "Column: 23, Selected False, Rank: 61.000\n",
            "Column: 24, Selected False, Rank: 74.000\n",
            "Column: 25, Selected False, Rank: 101.000\n",
            "Column: 26, Selected False, Rank: 102.000\n",
            "Column: 27, Selected False, Rank: 2.000\n",
            "Column: 28, Selected False, Rank: 55.000\n",
            "Column: 29, Selected False, Rank: 3.000\n",
            "Column: 30, Selected False, Rank: 15.000\n",
            "Column: 31, Selected False, Rank: 98.000\n",
            "Column: 32, Selected True, Rank: 1.000\n",
            "Column: 33, Selected False, Rank: 87.000\n",
            "Column: 34, Selected False, Rank: 90.000\n",
            "Column: 35, Selected False, Rank: 37.000\n",
            "Column: 36, Selected False, Rank: 64.000\n",
            "Column: 37, Selected False, Rank: 38.000\n",
            "Column: 38, Selected False, Rank: 71.000\n",
            "Column: 39, Selected False, Rank: 44.000\n",
            "Column: 40, Selected True, Rank: 1.000\n",
            "Column: 41, Selected True, Rank: 1.000\n",
            "Column: 42, Selected False, Rank: 11.000\n",
            "Column: 43, Selected False, Rank: 49.000\n",
            "Column: 44, Selected False, Rank: 67.000\n",
            "Column: 45, Selected True, Rank: 1.000\n",
            "Column: 46, Selected False, Rank: 32.000\n",
            "Column: 47, Selected False, Rank: 60.000\n",
            "Column: 48, Selected False, Rank: 80.000\n",
            "Column: 49, Selected False, Rank: 42.000\n",
            "Column: 50, Selected False, Rank: 58.000\n",
            "Column: 51, Selected False, Rank: 8.000\n",
            "Column: 52, Selected False, Rank: 79.000\n",
            "Column: 53, Selected False, Rank: 99.000\n",
            "Column: 54, Selected False, Rank: 94.000\n",
            "Column: 55, Selected False, Rank: 70.000\n",
            "Column: 56, Selected True, Rank: 1.000\n",
            "Column: 57, Selected False, Rank: 88.000\n",
            "Column: 58, Selected True, Rank: 1.000\n",
            "Column: 59, Selected True, Rank: 1.000\n",
            "Column: 60, Selected True, Rank: 1.000\n",
            "Column: 61, Selected False, Rank: 72.000\n",
            "Column: 62, Selected False, Rank: 41.000\n",
            "Column: 63, Selected True, Rank: 1.000\n",
            "Column: 64, Selected False, Rank: 53.000\n",
            "Column: 65, Selected False, Rank: 59.000\n",
            "Column: 66, Selected False, Rank: 6.000\n",
            "Column: 67, Selected False, Rank: 96.000\n",
            "Column: 68, Selected False, Rank: 10.000\n",
            "Column: 69, Selected False, Rank: 20.000\n",
            "Column: 70, Selected False, Rank: 39.000\n",
            "Column: 71, Selected False, Rank: 30.000\n",
            "Column: 72, Selected False, Rank: 17.000\n",
            "Column: 73, Selected True, Rank: 1.000\n",
            "Column: 74, Selected False, Rank: 84.000\n",
            "Column: 75, Selected False, Rank: 16.000\n",
            "Column: 76, Selected False, Rank: 13.000\n",
            "Column: 77, Selected False, Rank: 25.000\n",
            "Column: 78, Selected False, Rank: 92.000\n",
            "Column: 79, Selected False, Rank: 40.000\n",
            "Column: 80, Selected False, Rank: 52.000\n",
            "Column: 81, Selected False, Rank: 18.000\n",
            "Column: 82, Selected True, Rank: 1.000\n",
            "Column: 83, Selected False, Rank: 45.000\n",
            "Column: 84, Selected False, Rank: 54.000\n",
            "Column: 85, Selected False, Rank: 21.000\n",
            "Column: 86, Selected False, Rank: 75.000\n",
            "Column: 87, Selected True, Rank: 1.000\n",
            "Column: 88, Selected False, Rank: 63.000\n",
            "Column: 89, Selected False, Rank: 56.000\n",
            "Column: 90, Selected True, Rank: 1.000\n",
            "Column: 91, Selected False, Rank: 34.000\n",
            "Column: 92, Selected True, Rank: 1.000\n",
            "Column: 93, Selected False, Rank: 105.000\n",
            "Column: 94, Selected True, Rank: 1.000\n",
            "Column: 95, Selected False, Rank: 104.000\n",
            "Column: 96, Selected False, Rank: 100.000\n",
            "Column: 97, Selected False, Rank: 103.000\n",
            "Column: 98, Selected False, Rank: 31.000\n",
            "Column: 99, Selected False, Rank: 12.000\n",
            "Column: 100, Selected True, Rank: 1.000\n",
            "Column: 101, Selected True, Rank: 1.000\n",
            "Column: 102, Selected True, Rank: 1.000\n",
            "Column: 103, Selected False, Rank: 26.000\n",
            "Column: 104, Selected False, Rank: 51.000\n",
            "Column: 105, Selected False, Rank: 27.000\n",
            "Column: 106, Selected False, Rank: 28.000\n",
            "Column: 107, Selected False, Rank: 86.000\n",
            "Column: 108, Selected False, Rank: 23.000\n",
            "Column: 109, Selected False, Rank: 24.000\n",
            "Column: 110, Selected False, Rank: 33.000\n",
            "Column: 111, Selected True, Rank: 1.000\n",
            "Column: 112, Selected False, Rank: 22.000\n",
            "Column: 113, Selected True, Rank: 1.000\n",
            "Column: 114, Selected False, Rank: 68.000\n",
            "Column: 115, Selected False, Rank: 85.000\n",
            "Column: 116, Selected False, Rank: 77.000\n",
            "Column: 117, Selected False, Rank: 78.000\n",
            "Column: 118, Selected False, Rank: 36.000\n",
            "Column: 119, Selected False, Rank: 35.000\n",
            "Column: 120, Selected False, Rank: 19.000\n",
            "Column: 121, Selected False, Rank: 9.000\n",
            "Column: 122, Selected False, Rank: 81.000\n",
            "Column: 123, Selected False, Rank: 89.000\n",
            "Column: 124, Selected False, Rank: 82.000\n",
            "Column: 125, Selected False, Rank: 83.000\n",
            "Column: 126, Selected False, Rank: 14.000\n",
            "The number of samples with AD: 415\n",
            "The number of samples with no AD: 67\n",
            "Accuracy: 0.833 (0.040)\n",
            "Column: 0, Selected True, Rank: 1.000\n",
            "Column: 1, Selected False, Rank: 16.000\n",
            "Column: 2, Selected False, Rank: 3.000\n",
            "Column: 3, Selected False, Rank: 11.000\n",
            "Column: 4, Selected False, Rank: 47.000\n",
            "Column: 5, Selected True, Rank: 1.000\n",
            "Column: 6, Selected True, Rank: 1.000\n",
            "Column: 7, Selected False, Rank: 67.000\n",
            "Column: 8, Selected False, Rank: 59.000\n",
            "Column: 9, Selected False, Rank: 24.000\n",
            "Column: 10, Selected False, Rank: 66.000\n",
            "Column: 11, Selected False, Rank: 65.000\n",
            "Column: 12, Selected False, Rank: 83.000\n",
            "Column: 13, Selected False, Rank: 77.000\n",
            "Column: 14, Selected False, Rank: 21.000\n",
            "Column: 15, Selected False, Rank: 30.000\n",
            "Column: 16, Selected False, Rank: 17.000\n",
            "Column: 17, Selected False, Rank: 60.000\n",
            "Column: 18, Selected False, Rank: 87.000\n",
            "Column: 19, Selected False, Rank: 18.000\n",
            "Column: 20, Selected False, Rank: 39.000\n",
            "Column: 21, Selected False, Rank: 63.000\n",
            "Column: 22, Selected False, Rank: 91.000\n",
            "Column: 23, Selected False, Rank: 92.000\n",
            "Column: 24, Selected False, Rank: 82.000\n",
            "Column: 25, Selected False, Rank: 62.000\n",
            "Column: 26, Selected False, Rank: 61.000\n",
            "Column: 27, Selected False, Rank: 22.000\n",
            "Column: 28, Selected False, Rank: 57.000\n",
            "Column: 29, Selected False, Rank: 64.000\n",
            "Column: 30, Selected False, Rank: 50.000\n",
            "Column: 31, Selected False, Rank: 45.000\n",
            "Column: 32, Selected False, Rank: 73.000\n",
            "Column: 33, Selected False, Rank: 88.000\n",
            "Column: 34, Selected False, Rank: 71.000\n",
            "Column: 35, Selected False, Rank: 49.000\n",
            "Column: 36, Selected False, Rank: 6.000\n",
            "Column: 37, Selected False, Rank: 14.000\n",
            "Column: 38, Selected False, Rank: 27.000\n",
            "Column: 39, Selected False, Rank: 86.000\n",
            "Column: 40, Selected False, Rank: 5.000\n",
            "Column: 41, Selected False, Rank: 89.000\n",
            "Column: 42, Selected False, Rank: 72.000\n",
            "Column: 43, Selected False, Rank: 44.000\n",
            "Column: 44, Selected False, Rank: 79.000\n",
            "Column: 45, Selected False, Rank: 81.000\n",
            "Column: 46, Selected False, Rank: 80.000\n",
            "Column: 47, Selected False, Rank: 58.000\n",
            "Column: 48, Selected False, Rank: 29.000\n",
            "Column: 49, Selected False, Rank: 7.000\n",
            "Column: 50, Selected False, Rank: 53.000\n",
            "Column: 51, Selected True, Rank: 1.000\n",
            "Column: 52, Selected True, Rank: 1.000\n",
            "Column: 53, Selected False, Rank: 31.000\n",
            "Column: 54, Selected False, Rank: 33.000\n",
            "Column: 55, Selected False, Rank: 8.000\n",
            "Column: 56, Selected False, Rank: 28.000\n",
            "Column: 57, Selected False, Rank: 10.000\n",
            "Column: 58, Selected False, Rank: 48.000\n",
            "Column: 59, Selected False, Rank: 19.000\n",
            "Column: 60, Selected False, Rank: 75.000\n",
            "Column: 61, Selected False, Rank: 55.000\n",
            "Column: 62, Selected False, Rank: 15.000\n",
            "Column: 63, Selected False, Rank: 26.000\n",
            "Column: 64, Selected True, Rank: 1.000\n",
            "Column: 65, Selected False, Rank: 43.000\n",
            "Column: 66, Selected False, Rank: 76.000\n",
            "Column: 67, Selected False, Rank: 46.000\n",
            "Column: 68, Selected False, Rank: 74.000\n",
            "Column: 69, Selected False, Rank: 4.000\n",
            "Column: 70, Selected False, Rank: 32.000\n",
            "Column: 71, Selected False, Rank: 25.000\n",
            "Column: 72, Selected False, Rank: 78.000\n",
            "Column: 73, Selected False, Rank: 41.000\n",
            "Column: 74, Selected False, Rank: 69.000\n",
            "Column: 75, Selected True, Rank: 1.000\n",
            "Column: 76, Selected False, Rank: 2.000\n",
            "Column: 77, Selected True, Rank: 1.000\n",
            "Column: 78, Selected False, Rank: 93.000\n",
            "Column: 79, Selected False, Rank: 90.000\n",
            "Column: 80, Selected False, Rank: 94.000\n",
            "Column: 81, Selected False, Rank: 68.000\n",
            "Column: 82, Selected False, Rank: 13.000\n",
            "Column: 83, Selected False, Rank: 9.000\n",
            "Column: 84, Selected False, Rank: 52.000\n",
            "Column: 85, Selected False, Rank: 56.000\n",
            "Column: 86, Selected False, Rank: 70.000\n",
            "Column: 87, Selected False, Rank: 37.000\n",
            "Column: 88, Selected False, Rank: 35.000\n",
            "Column: 89, Selected False, Rank: 38.000\n",
            "Column: 90, Selected False, Rank: 20.000\n",
            "Column: 91, Selected True, Rank: 1.000\n",
            "Column: 92, Selected False, Rank: 85.000\n",
            "Column: 93, Selected False, Rank: 42.000\n",
            "Column: 94, Selected False, Rank: 51.000\n",
            "Column: 95, Selected False, Rank: 36.000\n",
            "Column: 96, Selected False, Rank: 34.000\n",
            "Column: 97, Selected False, Rank: 12.000\n",
            "Column: 98, Selected False, Rank: 54.000\n",
            "Column: 99, Selected False, Rank: 84.000\n",
            "Column: 100, Selected False, Rank: 23.000\n",
            "Column: 101, Selected False, Rank: 40.000\n",
            "The number of samples with AD: 415\n",
            "The number of samples with no AD: 67\n",
            "Accuracy: 0.816 (0.032)\n",
            "Column: 0, Selected True, Rank: 1.000\n",
            "Column: 1, Selected True, Rank: 1.000\n",
            "Column: 2, Selected False, Rank: 47.000\n",
            "Column: 3, Selected False, Rank: 84.000\n",
            "Column: 4, Selected True, Rank: 1.000\n",
            "Column: 5, Selected False, Rank: 76.000\n",
            "Column: 6, Selected False, Rank: 29.000\n",
            "Column: 7, Selected False, Rank: 86.000\n",
            "Column: 8, Selected False, Rank: 96.000\n",
            "Column: 9, Selected False, Rank: 26.000\n",
            "Column: 10, Selected True, Rank: 1.000\n",
            "Column: 11, Selected False, Rank: 99.000\n",
            "Column: 12, Selected False, Rank: 8.000\n",
            "Column: 13, Selected False, Rank: 100.000\n",
            "Column: 14, Selected False, Rank: 5.000\n",
            "Column: 15, Selected False, Rank: 80.000\n",
            "Column: 16, Selected False, Rank: 49.000\n",
            "Column: 17, Selected False, Rank: 45.000\n",
            "Column: 18, Selected False, Rank: 25.000\n",
            "Column: 19, Selected False, Rank: 58.000\n",
            "Column: 20, Selected False, Rank: 71.000\n",
            "Column: 21, Selected False, Rank: 51.000\n",
            "Column: 22, Selected False, Rank: 62.000\n",
            "Column: 23, Selected False, Rank: 98.000\n",
            "Column: 24, Selected False, Rank: 60.000\n",
            "Column: 25, Selected False, Rank: 59.000\n",
            "Column: 26, Selected False, Rank: 106.000\n",
            "Column: 27, Selected False, Rank: 94.000\n",
            "Column: 28, Selected False, Rank: 77.000\n",
            "Column: 29, Selected False, Rank: 50.000\n",
            "Column: 30, Selected False, Rank: 16.000\n",
            "Column: 31, Selected False, Rank: 36.000\n",
            "Column: 32, Selected False, Rank: 17.000\n",
            "Column: 33, Selected False, Rank: 102.000\n",
            "Column: 34, Selected False, Rank: 108.000\n",
            "Column: 35, Selected False, Rank: 107.000\n",
            "Column: 36, Selected True, Rank: 1.000\n",
            "Column: 37, Selected True, Rank: 1.000\n",
            "Column: 38, Selected False, Rank: 69.000\n",
            "Column: 39, Selected False, Rank: 41.000\n",
            "Column: 40, Selected False, Rank: 101.000\n",
            "Column: 41, Selected False, Rank: 64.000\n",
            "Column: 42, Selected False, Rank: 30.000\n",
            "Column: 43, Selected False, Rank: 40.000\n",
            "Column: 44, Selected False, Rank: 11.000\n",
            "Column: 45, Selected False, Rank: 87.000\n",
            "Column: 46, Selected False, Rank: 20.000\n",
            "Column: 47, Selected False, Rank: 55.000\n",
            "Column: 48, Selected False, Rank: 19.000\n",
            "Column: 49, Selected False, Rank: 2.000\n",
            "Column: 50, Selected False, Rank: 4.000\n",
            "Column: 51, Selected False, Rank: 66.000\n",
            "Column: 52, Selected False, Rank: 43.000\n",
            "Column: 53, Selected False, Rank: 95.000\n",
            "Column: 54, Selected True, Rank: 1.000\n",
            "Column: 55, Selected False, Rank: 90.000\n",
            "Column: 56, Selected False, Rank: 85.000\n",
            "Column: 57, Selected False, Rank: 10.000\n",
            "Column: 58, Selected False, Rank: 9.000\n",
            "Column: 59, Selected False, Rank: 15.000\n",
            "Column: 60, Selected False, Rank: 83.000\n",
            "Column: 61, Selected False, Rank: 37.000\n",
            "Column: 62, Selected False, Rank: 12.000\n",
            "Column: 63, Selected False, Rank: 56.000\n",
            "Column: 64, Selected False, Rank: 21.000\n",
            "Column: 65, Selected False, Rank: 61.000\n",
            "Column: 66, Selected True, Rank: 1.000\n",
            "Column: 67, Selected True, Rank: 1.000\n",
            "Column: 68, Selected False, Rank: 82.000\n",
            "Column: 69, Selected False, Rank: 92.000\n",
            "Column: 70, Selected True, Rank: 1.000\n",
            "Column: 71, Selected False, Rank: 6.000\n",
            "Column: 72, Selected False, Rank: 42.000\n",
            "Column: 73, Selected False, Rank: 97.000\n",
            "Column: 74, Selected False, Rank: 39.000\n",
            "Column: 75, Selected False, Rank: 46.000\n",
            "Column: 76, Selected False, Rank: 70.000\n",
            "Column: 77, Selected True, Rank: 1.000\n",
            "Column: 78, Selected False, Rank: 78.000\n",
            "Column: 79, Selected False, Rank: 7.000\n",
            "Column: 80, Selected False, Rank: 93.000\n",
            "Column: 81, Selected False, Rank: 3.000\n",
            "Column: 82, Selected False, Rank: 75.000\n",
            "Column: 83, Selected False, Rank: 72.000\n",
            "Column: 84, Selected False, Rank: 53.000\n",
            "Column: 85, Selected False, Rank: 18.000\n",
            "Column: 86, Selected False, Rank: 48.000\n",
            "Column: 87, Selected True, Rank: 1.000\n",
            "Column: 88, Selected True, Rank: 1.000\n",
            "Column: 89, Selected True, Rank: 1.000\n",
            "Column: 90, Selected False, Rank: 63.000\n",
            "Column: 91, Selected False, Rank: 88.000\n",
            "Column: 92, Selected False, Rank: 57.000\n",
            "Column: 93, Selected False, Rank: 13.000\n",
            "Column: 94, Selected False, Rank: 79.000\n",
            "Column: 95, Selected False, Rank: 22.000\n",
            "Column: 96, Selected False, Rank: 91.000\n",
            "Column: 97, Selected False, Rank: 104.000\n",
            "Column: 98, Selected False, Rank: 103.000\n",
            "Column: 99, Selected False, Rank: 105.000\n",
            "Column: 100, Selected False, Rank: 27.000\n",
            "Column: 101, Selected True, Rank: 1.000\n",
            "Column: 102, Selected True, Rank: 1.000\n",
            "Column: 103, Selected False, Rank: 28.000\n",
            "Column: 104, Selected True, Rank: 1.000\n",
            "Column: 105, Selected False, Rank: 23.000\n",
            "Column: 106, Selected False, Rank: 54.000\n",
            "Column: 107, Selected False, Rank: 31.000\n",
            "Column: 108, Selected True, Rank: 1.000\n",
            "Column: 109, Selected False, Rank: 68.000\n",
            "Column: 110, Selected False, Rank: 73.000\n",
            "Column: 111, Selected False, Rank: 14.000\n",
            "Column: 112, Selected True, Rank: 1.000\n",
            "Column: 113, Selected False, Rank: 24.000\n",
            "Column: 114, Selected False, Rank: 81.000\n",
            "Column: 115, Selected False, Rank: 44.000\n",
            "Column: 116, Selected False, Rank: 52.000\n",
            "Column: 117, Selected False, Rank: 65.000\n",
            "Column: 118, Selected False, Rank: 74.000\n",
            "Column: 119, Selected False, Rank: 34.000\n",
            "Column: 120, Selected False, Rank: 32.000\n",
            "Column: 121, Selected True, Rank: 1.000\n",
            "Column: 122, Selected False, Rank: 89.000\n",
            "Column: 123, Selected False, Rank: 33.000\n",
            "Column: 124, Selected False, Rank: 67.000\n",
            "Column: 125, Selected False, Rank: 35.000\n",
            "Column: 126, Selected False, Rank: 38.000\n",
            "The number of samples with AD: 415\n",
            "The number of samples with no AD: 67\n",
            "Accuracy: 0.829 (0.041)\n",
            "Column: 0, Selected True, Rank: 1.000\n",
            "Column: 1, Selected True, Rank: 1.000\n",
            "Column: 2, Selected True, Rank: 1.000\n",
            "Column: 3, Selected True, Rank: 1.000\n",
            "Column: 4, Selected False, Rank: 31.000\n",
            "Column: 5, Selected True, Rank: 1.000\n",
            "Column: 6, Selected True, Rank: 1.000\n",
            "Column: 7, Selected False, Rank: 37.000\n",
            "Column: 8, Selected False, Rank: 32.000\n",
            "Column: 9, Selected False, Rank: 33.000\n",
            "Column: 10, Selected True, Rank: 1.000\n",
            "Column: 11, Selected False, Rank: 27.000\n",
            "Column: 12, Selected True, Rank: 1.000\n",
            "Column: 13, Selected True, Rank: 1.000\n",
            "Column: 14, Selected False, Rank: 48.000\n",
            "Column: 15, Selected True, Rank: 1.000\n",
            "Column: 16, Selected False, Rank: 24.000\n",
            "Column: 17, Selected False, Rank: 26.000\n",
            "Column: 18, Selected False, Rank: 25.000\n",
            "Column: 19, Selected False, Rank: 49.000\n",
            "Column: 20, Selected False, Rank: 34.000\n",
            "Column: 21, Selected False, Rank: 21.000\n",
            "Column: 22, Selected False, Rank: 50.000\n",
            "Column: 23, Selected False, Rank: 20.000\n",
            "Column: 24, Selected False, Rank: 54.000\n",
            "Column: 25, Selected False, Rank: 55.000\n",
            "Column: 26, Selected True, Rank: 1.000\n",
            "Column: 27, Selected True, Rank: 1.000\n",
            "Column: 28, Selected True, Rank: 1.000\n",
            "Column: 29, Selected True, Rank: 1.000\n",
            "Column: 30, Selected True, Rank: 1.000\n",
            "Column: 31, Selected True, Rank: 1.000\n",
            "Column: 32, Selected True, Rank: 1.000\n",
            "Column: 33, Selected True, Rank: 1.000\n",
            "Column: 34, Selected True, Rank: 1.000\n",
            "Column: 35, Selected False, Rank: 14.000\n",
            "Column: 36, Selected False, Rank: 46.000\n",
            "Column: 37, Selected True, Rank: 1.000\n",
            "Column: 38, Selected True, Rank: 1.000\n",
            "Column: 39, Selected False, Rank: 11.000\n",
            "Column: 40, Selected True, Rank: 1.000\n",
            "Column: 41, Selected True, Rank: 1.000\n",
            "Column: 42, Selected True, Rank: 1.000\n",
            "Column: 43, Selected False, Rank: 28.000\n",
            "Column: 44, Selected False, Rank: 23.000\n",
            "Column: 45, Selected True, Rank: 1.000\n",
            "Column: 46, Selected True, Rank: 1.000\n",
            "Column: 47, Selected True, Rank: 1.000\n",
            "Column: 48, Selected False, Rank: 5.000\n",
            "Column: 49, Selected True, Rank: 1.000\n",
            "Column: 50, Selected True, Rank: 1.000\n",
            "Column: 51, Selected False, Rank: 7.000\n",
            "Column: 52, Selected True, Rank: 1.000\n",
            "Column: 53, Selected True, Rank: 1.000\n",
            "Column: 54, Selected False, Rank: 43.000\n",
            "Column: 55, Selected False, Rank: 35.000\n",
            "Column: 56, Selected True, Rank: 1.000\n",
            "Column: 57, Selected False, Rank: 16.000\n",
            "Column: 58, Selected False, Rank: 36.000\n",
            "Column: 59, Selected True, Rank: 1.000\n",
            "Column: 60, Selected True, Rank: 1.000\n",
            "Column: 61, Selected False, Rank: 6.000\n",
            "Column: 62, Selected False, Rank: 40.000\n",
            "Column: 63, Selected False, Rank: 30.000\n",
            "Column: 64, Selected False, Rank: 45.000\n",
            "Column: 65, Selected True, Rank: 1.000\n",
            "Column: 66, Selected False, Rank: 29.000\n",
            "Column: 67, Selected True, Rank: 1.000\n",
            "Column: 68, Selected False, Rank: 51.000\n",
            "Column: 69, Selected False, Rank: 39.000\n",
            "Column: 70, Selected True, Rank: 1.000\n",
            "Column: 71, Selected False, Rank: 41.000\n",
            "Column: 72, Selected True, Rank: 1.000\n",
            "Column: 73, Selected True, Rank: 1.000\n",
            "Column: 74, Selected False, Rank: 22.000\n",
            "Column: 75, Selected True, Rank: 1.000\n",
            "Column: 76, Selected False, Rank: 44.000\n",
            "Column: 77, Selected True, Rank: 1.000\n",
            "Column: 78, Selected False, Rank: 52.000\n",
            "Column: 79, Selected True, Rank: 1.000\n",
            "Column: 80, Selected False, Rank: 47.000\n",
            "Column: 81, Selected False, Rank: 10.000\n",
            "Column: 82, Selected False, Rank: 19.000\n",
            "Column: 83, Selected True, Rank: 1.000\n",
            "Column: 84, Selected False, Rank: 56.000\n",
            "Column: 85, Selected False, Rank: 53.000\n",
            "Column: 86, Selected False, Rank: 15.000\n",
            "Column: 87, Selected True, Rank: 1.000\n",
            "Column: 88, Selected True, Rank: 1.000\n",
            "Column: 89, Selected False, Rank: 42.000\n",
            "Column: 90, Selected True, Rank: 1.000\n",
            "Column: 91, Selected True, Rank: 1.000\n",
            "Column: 92, Selected False, Rank: 13.000\n",
            "Column: 93, Selected False, Rank: 12.000\n",
            "Column: 94, Selected True, Rank: 1.000\n",
            "Column: 95, Selected True, Rank: 1.000\n",
            "Column: 96, Selected False, Rank: 38.000\n",
            "Column: 97, Selected False, Rank: 17.000\n",
            "Column: 98, Selected True, Rank: 1.000\n",
            "Column: 99, Selected False, Rank: 4.000\n",
            "Column: 100, Selected False, Rank: 3.000\n",
            "Column: 101, Selected False, Rank: 2.000\n",
            "Column: 102, Selected False, Rank: 9.000\n",
            "Column: 103, Selected False, Rank: 18.000\n",
            "Column: 104, Selected False, Rank: 8.000\n",
            "The number of samples with AD: 416\n",
            "The number of samples with no AD: 68\n",
            "Accuracy: 0.825 (0.038)\n",
            "Column: 0, Selected False, Rank: 49.000\n",
            "Column: 1, Selected True, Rank: 1.000\n",
            "Column: 2, Selected False, Rank: 15.000\n",
            "Column: 3, Selected False, Rank: 2.000\n",
            "Column: 4, Selected False, Rank: 19.000\n",
            "Column: 5, Selected True, Rank: 1.000\n",
            "Column: 6, Selected True, Rank: 1.000\n",
            "Column: 7, Selected True, Rank: 1.000\n",
            "Column: 8, Selected False, Rank: 80.000\n",
            "Column: 9, Selected False, Rank: 59.000\n",
            "Column: 10, Selected False, Rank: 86.000\n",
            "Column: 11, Selected True, Rank: 1.000\n",
            "Column: 12, Selected False, Rank: 47.000\n",
            "Column: 13, Selected False, Rank: 111.000\n",
            "Column: 14, Selected False, Rank: 94.000\n",
            "Column: 15, Selected False, Rank: 102.000\n",
            "Column: 16, Selected False, Rank: 78.000\n",
            "Column: 17, Selected False, Rank: 82.000\n",
            "Column: 18, Selected False, Rank: 91.000\n",
            "Column: 19, Selected False, Rank: 92.000\n",
            "Column: 20, Selected False, Rank: 88.000\n",
            "Column: 21, Selected False, Rank: 81.000\n",
            "Column: 22, Selected False, Rank: 67.000\n",
            "Column: 23, Selected False, Rank: 72.000\n",
            "Column: 24, Selected True, Rank: 1.000\n",
            "Column: 25, Selected False, Rank: 108.000\n",
            "Column: 26, Selected False, Rank: 100.000\n",
            "Column: 27, Selected False, Rank: 114.000\n",
            "Column: 28, Selected False, Rank: 113.000\n",
            "Column: 29, Selected False, Rank: 6.000\n",
            "Column: 30, Selected False, Rank: 99.000\n",
            "Column: 31, Selected False, Rank: 12.000\n",
            "Column: 32, Selected False, Rank: 26.000\n",
            "Column: 33, Selected False, Rank: 93.000\n",
            "Column: 34, Selected False, Rank: 51.000\n",
            "Column: 35, Selected False, Rank: 70.000\n",
            "Column: 36, Selected False, Rank: 60.000\n",
            "Column: 37, Selected False, Rank: 25.000\n",
            "Column: 38, Selected False, Rank: 107.000\n",
            "Column: 39, Selected False, Rank: 97.000\n",
            "Column: 40, Selected False, Rank: 84.000\n",
            "Column: 41, Selected False, Rank: 10.000\n",
            "Column: 42, Selected False, Rank: 37.000\n",
            "Column: 43, Selected False, Rank: 68.000\n",
            "Column: 44, Selected False, Rank: 54.000\n",
            "Column: 45, Selected False, Rank: 20.000\n",
            "Column: 46, Selected False, Rank: 106.000\n",
            "Column: 47, Selected False, Rank: 3.000\n",
            "Column: 48, Selected False, Rank: 77.000\n",
            "Column: 49, Selected False, Rank: 89.000\n",
            "Column: 50, Selected False, Rank: 7.000\n",
            "Column: 51, Selected False, Rank: 104.000\n",
            "Column: 52, Selected False, Rank: 76.000\n",
            "Column: 53, Selected False, Rank: 53.000\n",
            "Column: 54, Selected False, Rank: 9.000\n",
            "Column: 55, Selected False, Rank: 57.000\n",
            "Column: 56, Selected False, Rank: 40.000\n",
            "Column: 57, Selected False, Rank: 33.000\n",
            "Column: 58, Selected False, Rank: 48.000\n",
            "Column: 59, Selected False, Rank: 18.000\n",
            "Column: 60, Selected False, Rank: 21.000\n",
            "Column: 61, Selected True, Rank: 1.000\n",
            "Column: 62, Selected False, Rank: 69.000\n",
            "Column: 63, Selected True, Rank: 1.000\n",
            "Column: 64, Selected True, Rank: 1.000\n",
            "Column: 65, Selected True, Rank: 1.000\n",
            "Column: 66, Selected False, Rank: 74.000\n",
            "Column: 67, Selected False, Rank: 50.000\n",
            "Column: 68, Selected True, Rank: 1.000\n",
            "Column: 69, Selected False, Rank: 29.000\n",
            "Column: 70, Selected False, Rank: 101.000\n",
            "Column: 71, Selected False, Rank: 90.000\n",
            "Column: 72, Selected False, Rank: 61.000\n",
            "Column: 73, Selected True, Rank: 1.000\n",
            "Column: 74, Selected False, Rank: 35.000\n",
            "Column: 75, Selected False, Rank: 98.000\n",
            "Column: 76, Selected False, Rank: 87.000\n",
            "Column: 77, Selected False, Rank: 28.000\n",
            "Column: 78, Selected False, Rank: 4.000\n",
            "Column: 79, Selected False, Rank: 105.000\n",
            "Column: 80, Selected False, Rank: 36.000\n",
            "Column: 81, Selected False, Rank: 23.000\n",
            "Column: 82, Selected False, Rank: 66.000\n",
            "Column: 83, Selected False, Rank: 8.000\n",
            "Column: 84, Selected False, Rank: 45.000\n",
            "Column: 85, Selected False, Rank: 103.000\n",
            "Column: 86, Selected False, Rank: 30.000\n",
            "Column: 87, Selected True, Rank: 1.000\n",
            "Column: 88, Selected False, Rank: 71.000\n",
            "Column: 89, Selected True, Rank: 1.000\n",
            "Column: 90, Selected False, Rank: 22.000\n",
            "Column: 91, Selected True, Rank: 1.000\n",
            "Column: 92, Selected False, Rank: 46.000\n",
            "Column: 93, Selected False, Rank: 52.000\n",
            "Column: 94, Selected False, Rank: 43.000\n",
            "Column: 95, Selected True, Rank: 1.000\n",
            "Column: 96, Selected False, Rank: 56.000\n",
            "Column: 97, Selected False, Rank: 75.000\n",
            "Column: 98, Selected False, Rank: 5.000\n",
            "Column: 99, Selected False, Rank: 79.000\n",
            "Column: 100, Selected False, Rank: 65.000\n",
            "Column: 101, Selected False, Rank: 24.000\n",
            "Column: 102, Selected False, Rank: 112.000\n",
            "Column: 103, Selected False, Rank: 115.000\n",
            "Column: 104, Selected False, Rank: 96.000\n",
            "Column: 105, Selected False, Rank: 39.000\n",
            "Column: 106, Selected True, Rank: 1.000\n",
            "Column: 107, Selected False, Rank: 55.000\n",
            "Column: 108, Selected True, Rank: 1.000\n",
            "Column: 109, Selected False, Rank: 42.000\n",
            "Column: 110, Selected False, Rank: 41.000\n",
            "Column: 111, Selected False, Rank: 11.000\n",
            "Column: 112, Selected False, Rank: 34.000\n",
            "Column: 113, Selected False, Rank: 27.000\n",
            "Column: 114, Selected False, Rank: 85.000\n",
            "Column: 115, Selected False, Rank: 32.000\n",
            "Column: 116, Selected False, Rank: 17.000\n",
            "Column: 117, Selected False, Rank: 95.000\n",
            "Column: 118, Selected False, Rank: 109.000\n",
            "Column: 119, Selected False, Rank: 16.000\n",
            "Column: 120, Selected False, Rank: 62.000\n",
            "Column: 121, Selected False, Rank: 64.000\n",
            "Column: 122, Selected False, Rank: 31.000\n",
            "Column: 123, Selected False, Rank: 63.000\n",
            "Column: 124, Selected False, Rank: 44.000\n",
            "Column: 125, Selected False, Rank: 14.000\n",
            "Column: 126, Selected False, Rank: 110.000\n",
            "Column: 127, Selected False, Rank: 13.000\n",
            "Column: 128, Selected False, Rank: 73.000\n",
            "Column: 129, Selected False, Rank: 83.000\n",
            "Column: 130, Selected True, Rank: 1.000\n",
            "Column: 131, Selected False, Rank: 38.000\n",
            "Column: 132, Selected False, Rank: 58.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lz1j90BsoXH",
        "outputId": "bd61a61d-5a79-4a0e-b0a7-91269274ca40"
      },
      "source": [
        "# Now, only select the features that were chosen in 2 folds or more to ensure stability\n",
        "unique_features = list(set(chosen_features))\n",
        "freq_features = [chosen_features.count(f) for f in unique_features]\n",
        "dict_features = dict(zip(unique_features, freq_features))\n",
        "dict_features = {k: v for k,v in dict_features.items() if v > 2}\n",
        "print(f'Number of features chosen: {len(dict_features)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwdpnSiSJtBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469bad26-92be-4362-cb87-eccef7295e42"
      },
      "source": [
        "# From all selected features, only select the features that were chosen in \n",
        "# 2 folds or more to ensure stability and generalizability\n",
        "unique_features = list(set(chosen_features))\n",
        "freq_features = [chosen_features.count(f) for f in unique_features]\n",
        "dict_features = dict(zip(unique_features, freq_features))\n",
        "dict_features = {k: v for k,v in dict_features.items() if v > 2}\n",
        "print(f'Number of features chosen: {len(dict_features)}')\n",
        "\n",
        "# Now, take the features from the dictionary and \n",
        "# select the right columns from the dataframe\n",
        "final_features = list(dict_features.keys())\n",
        "\n",
        "# Then select the right columns\n",
        "df_select = df_sig_ft[final_features]\n",
        "print(df_select.columns)\n",
        "\n",
        "# Also, select the features in the test dataset\n",
        "X_test_select = df_sig_ft_test[final_features]\n",
        "print(X_test_select)\n",
        "\n",
        "# Convert dataframes and lists to numpy arrays\n",
        "arr_select = df_select.to_numpy()\n",
        "array_test_select = X_test_select.to_numpy()\n",
        "labels_bin = np.array(labels_bin)\n",
        "labels_bin_test = np.array(labels_bin_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features chosen: 13\n",
            "Index(['hf_quartile_range', 'tf_Gabor_0.5A0.0min', 'tf_LBP_skew_R8_P24',\n",
            "       'tf_Gabor_0.05A0.0std', 'tf_Gabor_0.05A0.0skew', 'tf_Gabor_0.05A0.0min',\n",
            "       'tf_GLSZM_GrayLevelNonUniformity', 'tf_Gabor_0.05A0.79mean',\n",
            "       'hf_entropy', 'hf_peak', 'tf_Gabor_0.05A2.36min', 'tf_LBP_std_R3_P12',\n",
            "       'tf_Gabor_0.2A0.79min'],\n",
            "      dtype='object')\n",
            "     hf_quartile_range  ...  tf_Gabor_0.2A0.79min\n",
            "0             0.708486  ...              0.640587\n",
            "1             0.716360  ...              0.709755\n",
            "2             0.294083  ...              0.581258\n",
            "3             0.105598  ...              0.832698\n",
            "4             0.258481  ...              0.770761\n",
            "..                 ...  ...                   ...\n",
            "166           0.096957  ...              0.697784\n",
            "167           0.234038  ...              0.640300\n",
            "168           0.116245  ...              0.579254\n",
            "169           0.500093  ...              0.523838\n",
            "170           0.081010  ...              0.707345\n",
            "\n",
            "[171 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv1hmpUPabj4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05ebdff5-6199-43a7-8177-558c49d16e8e"
      },
      "source": [
        "# Visualize the features in scatter plots\n",
        "feat_comb = list(it.combinations(final_features, 2))\n",
        "for features in feat_comb:\n",
        "    plt.figure()\n",
        "    seaborn.scatterplot(x=features[0],\n",
        "                        y=features[1],\n",
        "                        hue=labels_bin,\n",
        "                        data=df_select)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MlbKShSob_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f513dc1-95a0-4d63-c495-e7980a0c94e4"
      },
      "source": [
        "# Train classifier\n",
        "\n",
        "# Create empty lists to save the scores and chosen hyperparameters in\n",
        "scores_val = []\n",
        "scores_train = []\n",
        "f1_scores_train = []\n",
        "f1_scores_val = []\n",
        "\n",
        "C_select = []\n",
        "gamma_select = []\n",
        "kernel_select = []\n",
        "\n",
        "for train, val in skf.split(arr_select, labels_bin):\n",
        "    print('train -  {}   |   val -  {}'.format(np.bincount(labels_bin[train]),\n",
        "                                               np.bincount(labels_bin[val])))\n",
        "    svm_clf = svm.SVC(probability=True, random_state=42)\n",
        "    params_tuning = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
        "    clf = RandomizedSearchCV(svm_clf, params_tuning)\n",
        "    clf.fit(arr_select[train], labels_bin[train])\n",
        "    y_pred_train = clf.predict(arr_select[train])\n",
        "    y_pred_val = clf.predict(arr_select[val])\n",
        "\n",
        "    scores_val.append(clf.score(arr_select[val], labels_bin[val]))\n",
        "    scores_train.append(clf.score(arr_select[train], labels_bin[train]))\n",
        "    C_select.append(clf.best_estimator_.C)\n",
        "    gamma_select.append(clf.best_estimator_.gamma)\n",
        "    kernel_select.append(clf.best_estimator_.kernel)\n",
        "    f1_scores_train.append(metrics.f1_score(y_pred_train, labels_bin[train]))\n",
        "    f1_scores_val.append(metrics.f1_score(y_pred_val, labels_bin[val]))\n",
        "\n",
        "    print(f'Classifier score training set: {clf.score(arr_select[train], labels_bin[train])}')\n",
        "    print(f'Classifier score validation set: {clf.score(arr_select[val], labels_bin[val])}')\n",
        "    print(f'F1-score training set: {metrics.f1_score(y_pred_train, labels_bin[train])}')\n",
        "    print(f'F1-score validation set: {metrics.f1_score(y_pred_val, labels_bin[val])}')\n",
        "\n",
        "mean_scores_val = np.mean(scores_val)\n",
        "mean_scores_train = np.mean(scores_train)\n",
        "mean_f1_train = np.mean(f1_scores_train)\n",
        "mean_f1_val = np.mean(f1_scores_val)\n",
        "print(f'Mean scores training set: {mean_scores_train}')\n",
        "print(f'Mean score validation set: {mean_scores_val}')\n",
        "print(f'Mean f1 score training set: {mean_f1_train}')\n",
        "print(f'Mean f1 score validation set: {mean_f1_val}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train -  [332 215]   |   val -  [84 53]\n",
            "Classifier score training set: 0.8318098720292505\n",
            "Classifier score validation set: 0.8613138686131386\n",
            "F1-score training set: 0.7722772277227723\n",
            "F1-score validation set: 0.8256880733944955\n",
            "train -  [333 214]   |   val -  [83 54]\n",
            "Classifier score training set: 0.8482632541133455\n",
            "Classifier score validation set: 0.7956204379562044\n",
            "F1-score training set: 0.7970660146699265\n",
            "F1-score validation set: 0.7254901960784315\n",
            "train -  [333 214]   |   val -  [83 54]\n",
            "Classifier score training set: 0.8409506398537477\n",
            "Classifier score validation set: 0.8102189781021898\n",
            "F1-score training set: 0.7841191066997518\n",
            "F1-score validation set: 0.723404255319149\n",
            "train -  [333 214]   |   val -  [83 54]\n",
            "Classifier score training set: 0.829981718464351\n",
            "Classifier score validation set: 0.8613138686131386\n",
            "F1-score training set: 0.7759036144578313\n",
            "F1-score validation set: 0.8190476190476189\n",
            "train -  [333 215]   |   val -  [83 53]\n",
            "Classifier score training set: 0.8357664233576643\n",
            "Classifier score validation set: 0.8235294117647058\n",
            "F1-score training set: 0.7749999999999999\n",
            "F1-score validation set: 0.7551020408163266\n",
            "Mean scores training set: 0.8373543815636717\n",
            "Mean score validation set: 0.8303993130098755\n",
            "Mean f1 score training set: 0.7808731927100563\n",
            "Mean f1 score validation set: 0.7697464369312043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w48qy7lf8Rot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85bcb63-855b-4e99-fbfb-420def0aec62"
      },
      "source": [
        "# Now create a classifier with the right hyperparameters\n",
        "# Majority voting was used in order to choose the final hyperparameters\n",
        "C_final = max(set(C_select), key=C_select.count)\n",
        "kernel_final = max(set(kernel_select), key=kernel_select.count)\n",
        "gamma_final = max(set(gamma_select), key=gamma_select.count)\n",
        "params_final = {'C': C_final, 'gamma': gamma_final, 'kernel': kernel_final}\n",
        "print(f'The final value for C is: {C_final}')\n",
        "print(f'The final kernel is: {kernel_final}')\n",
        "print(f'The final value for gamma is: {gamma_final}')\n",
        "\n",
        "# Implement these hyperparameters and train a new classifier\n",
        "# using the entire training set\n",
        "clf_test = svm.SVC(random_state=42,\n",
        "                   gamma=gamma_final,\n",
        "                   C=C_final,\n",
        "                   kernel=kernel_final)\n",
        "clf_test.fit(arr_select, labels_bin)\n",
        "\n",
        "# Finally, apply the classifier to the test set and\n",
        "# compute the accuracy and F1-score\n",
        "accuracy_test = clf_test.score(array_test_select, labels_bin_test)\n",
        "print(f'The accuracy on the test set is {accuracy_test}')\n",
        "y_pred = clf_test.predict(array_test_select)\n",
        "f1_score_test = metrics.f1_score(y_pred, labels_bin_test)\n",
        "print(f'The f1-score on the test set is {f1_score_test}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkCGe4RXFOr9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "364db8ab-4eeb-4048-ae0b-783fbe80ae1c"
      },
      "source": [
        "# Plot ROC curve\n",
        "y_score = clf.predict_proba(array_test_select)\n",
        "plot_roc_curve(y_score, labels_bin_test)\n",
        "\n",
        "# Confusion matrix\n",
        "disp = plot_confusion_matrix(clf_test, array_test_select, labels_bin_test,\n",
        "                             display_labels=[\"AD\", \"CN\"],\n",
        "                             cmap=plt.cm.Blues,\n",
        "                             normalize=None)\n",
        "disp.ax_.set_title(\"Confusion matrix, without normalization\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}